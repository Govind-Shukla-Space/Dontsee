# jobs/run_queries.py
from pyspark.sql import SparkSession
from config.db_config import DB_CONFIG

def run_batch_queries():
    spark = (
        SparkSession.builder
        .appName("CricketBatchQueries")
        .config("spark.jars", DB_CONFIG["jdbc_jar"])
        .getOrCreate()
    )

    # === Load historical data ===
    dim_player = spark.read.format("jdbc").options(
        url=DB_CONFIG["target_url"],
        dbtable="dim_player",
        user=DB_CONFIG["user"],
        password=DB_CONFIG["password"],
        driver=DB_CONFIG["driver"]
    ).load()

    dim_match = spark.read.format("jdbc").options(
        url=DB_CONFIG["target_url"],
        dbtable="dim_match",
        user=DB_CONFIG["user"],
        password=DB_CONFIG["password"],
        driver=DB_CONFIG["driver"]
    ).load()

    fact_stats = spark.read.format("jdbc").options(
        url=DB_CONFIG["target_url"],
        dbtable="fact_player_match_stats",
        user=DB_CONFIG["user"],
        password=DB_CONFIG["password"],
        driver=DB_CONFIG["driver"]
    ).load()

    # Register temp views
    dim_player.createOrReplaceTempView("dim_player")
    dim_match.createOrReplaceTempView("dim_match")
    fact_stats.createOrReplaceTempView("fact_player_match_stats")

    # === Example Historical Queries ===
    print("\nTop 10 Run Scorers (all time):")
    top_scorers = spark.sql("""
        SELECT p.playerName, SUM(f.runsScored) as totalRuns
        FROM fact_player_match_stats f
        JOIN dim_player p ON f.playerId = p.playerId
        GROUP BY p.playerName
        ORDER BY totalRuns DESC
        LIMIT 10
    """)
    top_scorers.show(truncate=False)

    print("\nBest Bowlers by Wickets (all time):")
    top_bowlers = spark.sql("""
        SELECT p.playerName, SUM(f.wickets) as totalWickets
        FROM fact_player_match_stats f
        JOIN dim_player p ON f.playerId = p.playerId
        GROUP BY p.playerName
        ORDER BY totalWickets DESC
        LIMIT 10
    """)
    top_bowlers.show(truncate=False)

    spark.stop()


if __name__ == "__main__":
    run_batch_queries()
# jobs/streaming_queries.py
from pyspark.sql import SparkSession

def run_streaming_queries():
    spark = (
        SparkSession.builder
        .appName("CricketStreamingQueries")
        .getOrCreate()
    )

    # Example: top 10 scorers live
    live_top_scorers = spark.sql("""
        SELECT playerId, SUM(runsScored) as totalRuns
        FROM live_fact_player_match_stats
        GROUP BY playerId
        ORDER BY totalRuns DESC
        LIMIT 10
    """)
    live_top_scorers.show(truncate=False)

    # Example: wickets by bowler live
    live_top_bowlers = spark.sql("""
        SELECT playerId, SUM(wickets) as totalWickets
        FROM live_fact_player_match_stats
        GROUP BY playerId
        ORDER BY totalWickets DESC
        LIMIT 10
    """)
    live_top_bowlers.show(truncate=False)

    spark.stop()


if __name__ == "__main__":
    run_streaming_queries()
