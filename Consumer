"""
Weather Producer - Milestone 1
Simulates IoT devices by sending weather data into Kafka topic: weather.readings
"""

import json
import time
import random
from kafka import KafkaProducer

TOPIC = "weather.readings"

def create_producer():
    return KafkaProducer(
        bootstrap_servers="localhost:9092",
        value_serializer=lambda v: json.dumps(v).encode("utf-8")
    )

if __name__ == "__main__":
    print("ðŸš€ Starting Weather Producer...")
    producer = create_producer()

    # Load dataset from JSON
    with open("data.json", "r") as f:
        records = json.load(f)

    # Loop forever simulating continuous IoT stream
    while True:
        record = random.choice(records)  # pick a random sensor reading

        # send to Kafka
        producer.send(TOPIC, value=record)
        producer.flush()

        print(f"âœ… Sent: {record}")
        time.sleep(1)  # simulate 1 reading/sec


consumer
"""
Weather Consumer - Milestone 1
Consumes messages from Kafka topic: weather.readings using PySpark Structured Streaming
"""

from pyspark.sql import SparkSession

TOPIC = "weather.readings"

if __name__ == "__main__":
    spark = SparkSession.builder \
        .appName("WeatherConsumer") \
        .master("local[*]") \
        .getOrCreate()

    spark.sparkContext.setLogLevel("WARN")

    # Read stream from Kafka
    df = spark.readStream \
        .format("kafka") \
        .option("kafka.bootstrap.servers", "localhost:9092") \
        .option("subscribe", TOPIC) \
        .option("startingOffsets", "latest") \
        .load()

    # Convert Kafka value (binary) â†’ string
    messages = df.selectExpr("CAST(value AS STRING)")

    query = messages.writeStream \
        .outputMode("append") \
        .format("console") \
        .option("truncate", False) \
        .start()

    query.awaitTermination()
